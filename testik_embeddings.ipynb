{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import dgeb\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dfs_lmdb = {}\n",
    "for data_type in ['train', 'valid', 'test']:\n",
    "    env = lmdb.open(f'HumanPPI/normal/{data_type}/')\n",
    "    res = []\n",
    "\n",
    "    with env.begin() as txn:\n",
    "        for key, value in txn.cursor():\n",
    "            if key == b'info' or key == b'length':\n",
    "                continue\n",
    "            res.append(json.loads(value))\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "    dfs_lmdb[data_type] = pd.DataFrame(res)\n",
    "\n",
    "df_lmdb = pd.concat(dfs_lmdb.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>seq_1</th>\n",
       "      <th>seq_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q01780</td>\n",
       "      <td>Q9Y333</td>\n",
       "      <td>MAPPSTREPRVLSATSATKSDGEMVLPGFPDADSFVKFALGSVVAV...</td>\n",
       "      <td>MLFYSFFKSLVGKDVVVELKNDLSICGTLHSVDQYLNIKLTDISVT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9P104</td>\n",
       "      <td>P06213</td>\n",
       "      <td>MASNFNDIVKQGYVRIRSRRLGIYQRCWLVFKKASSKGPKRLEKFS...</td>\n",
       "      <td>MATGGRRGAAAAPLLVAVAALLLGAAGHLYPGEVCPGMDIRNNLTR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O00300</td>\n",
       "      <td>P04004</td>\n",
       "      <td>MNNLLCCALVFLDISIKWTTQETFPPKYLHYDEETSHQLLCDKCPP...</td>\n",
       "      <td>MAPLRPLLILALLAWVALADQESCKGRCTEGFNVDKKCQCDELCSY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9UNY4</td>\n",
       "      <td>P22626</td>\n",
       "      <td>MEEVRCPEHGTFCFLKTGVRDGPNKGKSFYVCRADTCSFVRATDIP...</td>\n",
       "      <td>MEKTLETVPLERKKREKEQFRKLFIGGLSFETTEESLRNYYEQWGK...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q15139</td>\n",
       "      <td>Q02156</td>\n",
       "      <td>MSAPPVLRPPSPLLPVAAAAAAAAAALVPGSGPGPAPFLAPVAAPV...</td>\n",
       "      <td>MVVFNGLLKIKICEAVSLKPTAWSLRHAVGPRPQTFLLDPYIALNV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>P09429</td>\n",
       "      <td>Q92552</td>\n",
       "      <td>MGKGDPKKPRGKMSSYAFFVQTCREEHKKKHPDASVNFSEFSKKCS...</td>\n",
       "      <td>MAASIVRRGMLLARQVVLPQLSPAGKRYLLSSAYVDSHKWEAREKE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>O94763</td>\n",
       "      <td>Q96M27</td>\n",
       "      <td>MEAPTVETPPDPSPPSAPAPALVPLRAPDVARLREEQEKVVTNCQE...</td>\n",
       "      <td>MMEESGIETTPPGTPPPNPAGLAATAMSSTPVPLAATSSFSSPNVS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Q86TM3</td>\n",
       "      <td>Q96M27</td>\n",
       "      <td>MSHWAPEWKRAEANPRDLGASWDVRGSRGSGWSGPFGHQGPRAAGS...</td>\n",
       "      <td>MMEESGIETTPPGTPPPNPAGLAATAMSSTPVPLAATSSFSSPNVS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>O15151</td>\n",
       "      <td>Q9BY32</td>\n",
       "      <td>MTSFSTSAQCSTSDSACRISPGQINQVRPKLPLLKILHAAGAQGEM...</td>\n",
       "      <td>MAASLVGKKIVFVTGNAKKLEEVVQILGDKFPCTLVAQKIDLPEYQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>P52701</td>\n",
       "      <td>Q9BYC2</td>\n",
       "      <td>MSRQSTLYSFFPKSPALSDANKASARASREGGRAAAAPGASPSPGG...</td>\n",
       "      <td>MAALRLLASVLGRGVPAGGSGLALSQGCARCFATSPRLRAKFYADP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26733 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name_1  name_2                                              seq_1  \\\n",
       "0    Q01780  Q9Y333  MAPPSTREPRVLSATSATKSDGEMVLPGFPDADSFVKFALGSVVAV...   \n",
       "1    Q9P104  P06213  MASNFNDIVKQGYVRIRSRRLGIYQRCWLVFKKASSKGPKRLEKFS...   \n",
       "2    O00300  P04004  MNNLLCCALVFLDISIKWTTQETFPPKYLHYDEETSHQLLCDKCPP...   \n",
       "3    Q9UNY4  P22626  MEEVRCPEHGTFCFLKTGVRDGPNKGKSFYVCRADTCSFVRATDIP...   \n",
       "4    Q15139  Q02156  MSAPPVLRPPSPLLPVAAAAAAAAAALVPGSGPGPAPFLAPVAAPV...   \n",
       "..      ...     ...                                                ...   \n",
       "175  P09429  Q92552  MGKGDPKKPRGKMSSYAFFVQTCREEHKKKHPDASVNFSEFSKKCS...   \n",
       "176  O94763  Q96M27  MEAPTVETPPDPSPPSAPAPALVPLRAPDVARLREEQEKVVTNCQE...   \n",
       "177  Q86TM3  Q96M27  MSHWAPEWKRAEANPRDLGASWDVRGSRGSGWSGPFGHQGPRAAGS...   \n",
       "178  O15151  Q9BY32  MTSFSTSAQCSTSDSACRISPGQINQVRPKLPLLKILHAAGAQGEM...   \n",
       "179  P52701  Q9BYC2  MSRQSTLYSFFPKSPALSDANKASARASREGGRAAAAPGASPSPGG...   \n",
       "\n",
       "                                                 seq_2  label  \n",
       "0    MLFYSFFKSLVGKDVVVELKNDLSICGTLHSVDQYLNIKLTDISVT...      1  \n",
       "1    MATGGRRGAAAAPLLVAVAALLLGAAGHLYPGEVCPGMDIRNNLTR...      1  \n",
       "2    MAPLRPLLILALLAWVALADQESCKGRCTEGFNVDKKCQCDELCSY...      1  \n",
       "3    MEKTLETVPLERKKREKEQFRKLFIGGLSFETTEESLRNYYEQWGK...      1  \n",
       "4    MVVFNGLLKIKICEAVSLKPTAWSLRHAVGPRPQTFLLDPYIALNV...      1  \n",
       "..                                                 ...    ...  \n",
       "175  MAASIVRRGMLLARQVVLPQLSPAGKRYLLSSAYVDSHKWEAREKE...      0  \n",
       "176  MMEESGIETTPPGTPPPNPAGLAATAMSSTPVPLAATSSFSSPNVS...      0  \n",
       "177  MMEESGIETTPPGTPPPNPAGLAATAMSSTPVPLAATSSFSSPNVS...      0  \n",
       "178  MAASLVGKKIVFVTGNAKKLEEVVQILGDKFPCTLVAQKIDLPEYQ...      0  \n",
       "179  MAALRLLASVLGRGVPAGGSGLALSQGCARCFATSPRLRAKFYADP...      0  \n",
       "\n",
       "[26733 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_df(sequences, model_name):\n",
    "    model_name_for_file = model_name.replace('/', '-').replace(' ', '-').replace('_', '-')\n",
    "    f = Path(f'embeddings_{model_name_for_file}.parquet')\n",
    "    if f.exists():\n",
    "        return pd.read_parquet(f)\n",
    "\n",
    "    model = dgeb.get_model(model_name, layers=\"last\", batch_size=1, max_seq_length=2048)\n",
    "\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "        embeddings = model.encode(sequences)\n",
    "\n",
    "    df = pd.DataFrame({'sequence': sequences, 'embedding': list(embeddings.squeeze())})\n",
    "    df.to_parquet(f)\n",
    "    return df\n",
    "\n",
    "sequences = list(set(df_lmdb.seq_1) | set(df_lmdb.seq_2))\n",
    "\n",
    "embedding_by_sequence = {}\n",
    "for model_name in [\"esm3_sm_open_v1\", \"facebook/esm2_t33_650M_UR50D\"]:\n",
    "    embeddings_df = get_embeddings_df(sequences, model_name)\n",
    "    embedding_by_sequence[model_name] = {}\n",
    "    for elem in embeddings_df.itertuples():\n",
    "        embedding_by_sequence[model_name][elem.sequence] = elem.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "\n",
    "embeddings = []\n",
    "for elem in df_lmdb.itertuples():\n",
    "    emb1 = embedding_by_sequence[model_name][elem.seq_1]\n",
    "    emb2 = embedding_by_sequence[model_name][elem.seq_2]\n",
    "    emb = torch.cat([torch.from_numpy(emb1), torch.from_numpy(emb2)])\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = torch.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2412, -3.2344,  1.7555,  ..., -5.0823, -2.1633, -7.6051],\n",
       "        [ 0.3723,  1.4925, -3.8769,  ..., -1.4513,  3.1598,  0.7873],\n",
       "        [ 0.5665,  0.7051, -1.1807,  ..., -1.1339, -0.8480, -2.6322],\n",
       "        ...,\n",
       "        [ 0.5372, -5.0282, -0.3123,  ...,  1.4255,  0.5592, -0.4750],\n",
       "        [ 3.7329, -2.3684,  0.7646,  ..., -2.6803, -4.0307, -2.7534],\n",
       "        [ 1.2119, -4.5896, -1.4423,  ..., -0.2077,  0.6540,  1.7106]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='esm3_sm_open_v1'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8bab51703b42b8b2d767d4c288602e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_test_Accuracy_mean': np.float64(0.7944444444444444), 'best_test_Accuracy_std': np.float64(0.0), 'best_test_AUPRC_mean': np.float64(0.8571600308454443), 'best_test_AUPRC_std': np.float64(0.0), 'best_test_F1 Score_mean': np.float64(0.7784431137724551), 'best_test_F1 Score_std': np.float64(0.0), 'best_test_AUROC_mean': np.float64(0.8927625772285968), 'best_test_AUROC_std': np.float64(0.0)}\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(input_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.project(x)\n",
    "\n",
    "\n",
    "def classification_metrics(targets, predictions, threshold=0.5):\n",
    "    binary_predictions = (predictions >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(targets, binary_predictions)\n",
    "    f1 = f1_score(targets, binary_predictions)\n",
    "    auc_score = roc_auc_score(targets, predictions)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(targets, predictions)\n",
    "    auprc = auc(recall_vals, precision_vals)\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"AUPRC\": auprc,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUROC\": auc_score,\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, name, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for step, eval_batch in enumerate(loader):\n",
    "        embs, target = eval_batch\n",
    "        embs = embs.to(device)\n",
    "        target = target.to(device)\n",
    "        pred = model(embs).squeeze(-1)\n",
    "        pred = torch.sigmoid(pred)\n",
    "\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        targets.append(target.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "\n",
    "    metrics = classification_metrics(targets, preds)\n",
    "    return {f\"{name}_{k}\": i for k, i in metrics.items()}\n",
    "\n",
    "\n",
    "def calculate_mean_std(metrics):\n",
    "    aggregated_metrics = {}\n",
    "    for metric_dict in metrics:\n",
    "        for key, value in metric_dict.items():\n",
    "            if key not in aggregated_metrics:\n",
    "                aggregated_metrics[key] = []\n",
    "            aggregated_metrics[key].append(value)\n",
    "    mean_std_metrics = {}\n",
    "    for key, values in aggregated_metrics.items():\n",
    "        mean_std_metrics[key + \"_mean\"] = np.mean(values)\n",
    "        mean_std_metrics[key + \"_std\"] = np.std(values)\n",
    "    return mean_std_metrics\n",
    "\n",
    "\n",
    "model_name = [\"esm3_sm_open_v1\", \"facebook/esm2_t33_650M_UR50D\"][0]\n",
    "print(f'{model_name=}')\n",
    "\n",
    "datasets = {}\n",
    "for data_type in ['train', 'valid', 'test']:\n",
    "    embeddings = []\n",
    "    for elem in dfs_lmdb[data_type].itertuples():\n",
    "        emb1 = embedding_by_sequence[model_name][elem.seq_1]\n",
    "        emb2 = embedding_by_sequence[model_name][elem.seq_2]\n",
    "        emb = torch.cat([torch.from_numpy(emb1), torch.from_numpy(emb2)])\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    datasets[data_type] = TensorDataset(\n",
    "        torch.stack(embeddings),\n",
    "        torch.tensor(dfs_lmdb[data_type].label)\n",
    "    )\n",
    "\n",
    "all_metrics = []\n",
    "batch_size = 1000\n",
    "reps = 1\n",
    "\n",
    "monitor_metric=\"Accuracy\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs=100\n",
    "input_size = datasets['train'][0][0].shape[-1]\n",
    "output_size = 1\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "for rep in range(reps):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets['train'], batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets['valid'], batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets['test'], batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    torch.manual_seed(rep)\n",
    "\n",
    "    model = SimpleMLP(input_size, output_size).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=10\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_valid_metric = 0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        loss_accum = 0\n",
    "        model.train()\n",
    "        for step, train_batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            embs, target = train_batch\n",
    "            embs = embs.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            pred = model(embs)\n",
    "            loss = loss_fn(pred.squeeze(), target.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_accum += loss.detach().cpu().item()\n",
    "\n",
    "        test_metrics_dict = evaluate(model, test_loader, \"test\", device)\n",
    "        valid_metrics_dict = evaluate(model, valid_loader, \"valid\", device)\n",
    "\n",
    "        if valid_metrics_dict[f\"valid_{monitor_metric}\"] >= best_valid_metric:\n",
    "            best_test_metrics = test_metrics_dict\n",
    "            best_valid_metric = valid_metrics_dict[f\"valid_{monitor_metric}\"]\n",
    "\n",
    "        train_loss = loss_accum / (step + 1)\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    best_test_metrics = {f\"best_{k}\": i for k, i in best_test_metrics.items()}\n",
    "\n",
    "    all_metrics.append(best_test_metrics)\n",
    "\n",
    "print(calculate_mean_std(all_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
