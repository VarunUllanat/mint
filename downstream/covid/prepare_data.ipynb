{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a084344c-cfe3-4ea2-84a2-5f209caaafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "full_df = pd.read_csv('CoV-AbDab_080224.csv')\n",
    "ab_df = full_df[full_df['VHorVHH'] != 'ND']\n",
    "ab_df = full_df[full_df['VL'] != 'ND']\n",
    "ab_df = ab_df[ab_df['Ab or Nb'] == 'Ab']\n",
    "ab_df = ab_df[['Neutralising Vs', 'Not Neutralising Vs', 'VHorVHH', 'VL', 'Origin', 'Protein + Epitope', 'Name']]\n",
    "ab_df = ab_df.fillna('')\n",
    "ab_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1e91e55-e00b-43ec-bcc1-cca847d3f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_to_keep = ['B-cells; SARS-CoV2_WT Convalescent Patient (Unvaccinated)', \n",
    "                         'B-cells; SARS-CoV1 Human Patient; SARS-CoV2 Vaccinee',\n",
    "                         'B-cells; SARS-CoV2_WT Convalescent Patients',\n",
    "                         'B-cells; SARS-CoV2_WT Vaccinee (BBIBP-CoV)',\n",
    "                         'B-cells; SARS-CoV2_WT Vaccinee',\n",
    "                         'B-cells; SARS-CoV2_WT Human Patient',\n",
    "                         'B-cells; Unvaccinated SARS-CoV2_WT Human Patient',\n",
    "                         'B-cells; SARS-CoV2_Gamma Human Patient',\n",
    "                         'B-cells; SARS-CoV1 Human Patient',\n",
    "                         'B-cells (SARS-CoV2_Beta Human Patient)'\n",
    "                        ]\n",
    "\n",
    "binding_to_keep = [\"S; RBD\", \"S: RBD\", \"S; RBD/NTD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45ef5e95-f066-46e8-83f2-1e6cf1943c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = ab_df[ab_df['Origin'].isin(sources_to_keep)]\n",
    "source_df = source_df[source_df['Protein + Epitope'].isin(binding_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6418860-95fd-4389-a6b0-6e306b43a946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S; RBD        2207\n",
       "S: RBD           1\n",
       "S; RBD/NTD       1\n",
       "Name: Protein + Epitope, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df['Protein + Epitope'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5337c99-969d-4aef-b529-49c403cf2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_chains = []\n",
    "light_chains = []\n",
    "antigens = []\n",
    "target = []\n",
    "names = []\n",
    "origins = []\n",
    "\n",
    "for i,row in source_df.iterrows():\n",
    "    neut_ags = row['Neutralising Vs'].split(';')\n",
    "    no_neut_ags = row['Not Neutralising Vs'].split(';')\n",
    "    name = row['Name']\n",
    "    origin = row['Origin']\n",
    "\n",
    "    hc = row['VHorVHH']\n",
    "    lc = row['VL']\n",
    "\n",
    "    for n in neut_ags:\n",
    "        if n != '':\n",
    "            heavy_chains.append(hc)\n",
    "            light_chains.append(lc)\n",
    "            antigens.append(n)\n",
    "            target.append(1)\n",
    "            names.append(name)\n",
    "            origins.append(origin)\n",
    "\n",
    "    for n in no_neut_ags:\n",
    "        if n != '':\n",
    "            heavy_chains.append(hc)\n",
    "            light_chains.append(lc)\n",
    "            antigens.append(n)\n",
    "            target.append(0)\n",
    "            names.append(name)\n",
    "            origins.append(origin)\n",
    "\n",
    "interaction_df = pd.DataFrame({'names': names,\n",
    "                               'origins': origins, \n",
    "                               'heavy': heavy_chains, \n",
    "                              'light': light_chains,\n",
    "                              'antigens': antigens,\n",
    "                              'target': target})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc0b0bf4-8422-4058-be8a-afb1c32f0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_dict = {\n",
    "    'SARS-CoV2_WT': ['SARS-CoV2_WT', 'SARS-CoV2_WT (weak)', 'SARS-CoV2_WT and SARS-CoV1', 'SARS-CoV2_WT, SARS-CoV2_Delta', 'SARS-CoV2_WT_Delta (weak)', 'SARS-CoV2_WT (weak) , SARS-CoV2_Delta (weak)'],\n",
    "    'SARS-CoV2_Alpha': ['SARS-CoV2_Alpha', 'SARS-CoV2_Alpha (weak)'],\n",
    "    'SARS-CoV2_Beta': ['SARS-CoV2_Beta', 'SARS-CoV2_Beta (weak)', 'SRAS-CoV2_Beta'],\n",
    "    'SARS-CoV2_Delta': ['SARS-CoV2_Delta', 'SARS-CoV2_Delta (weak)'],\n",
    "    'SARS-CoV2_Epsilon': ['SARS-CoV2_Epsilon', 'SARS-CoV2_Epsilon (weak)'],\n",
    "    'SARS-CoV2_Gamma': ['SARS_CoV2_Gamma', 'SARS-CoV2_Gamma', 'SARS-CoV2_Gamma (weak)'],\n",
    "    'SARS-CoV2_Eta': ['SARS-CoV2_Eta', 'SARS-CoV2_Eta (weak)'],\n",
    "    'SARS-CoV2_Iota': ['SARS-CoV2_Iota', 'SARS-CoV2_Iota (weak)'],\n",
    "    'SARS-CoV2_Lambda': ['SARS-CoV2_Lambda', 'SARS-CoV2_Lambda (weak)'],\n",
    "    'SARS-CoV2_Kappa': ['SARS-CoV2_Kappa', 'SARS-CoV2_Kappa (weak)'],\n",
    "    'SARS-CoV2_Omicron-BA1': ['SARS-CoV2_Omicron-BA1', 'SARS-CoV2_Omicron-BA1 (weak)', 'SARS-CoV2_Omicron_BA1', 'SARS-CoV2_Omicron_BA1.1', 'SARS-CoV2_Omicron-BA1.1 (weak)'],\n",
    "    'SARS-CoV2_Omicron-BA2': ['SARS-CoV2_Omicron-BA2', 'SARS-CoV2_Omicron-BA2 (weak)', 'SARS_COV2_Omicron-BA2', 'SARS-CoV2_Omicron-BA2.12.1', 'SARS-CoV2_Omicron-BA2.12.1 (weak)', 'SARS-CoV2_Omicron-BA2.75', 'SARS-CoV2_Omicron-BA2.38', 'SARS-CoV2_Omicron-BA2.38 (weak)', 'SARS-CoV2_Omicron-BA2.75.1', 'SARS-CoV2_Omicron-BA2.75.5', 'SARS-CoV2_Omicron-BA2.75.5 (weak)'],\n",
    "    'SARS-CoV2_Omicron-BA4': ['SARS-CoV2_Omicron-BA4', 'SARS-CoV2_Omicron-BA4 (weak)', 'SARS-CoV2_Omicron-BA4/BA', 'SARS-CoV2_Omicron-BA4.6', 'SARS-CoV2_Omicron-BA4.6 (weak)', 'SARS-CoV2_Omicron-BA4.7', 'SARS-CoV2_Omicron-BA4.7 (weak)'],\n",
    "    'SARS-CoV2_Omicron-BA5': ['SARS-CoV2_Omicron-BA5', 'SARS-CoV2_Omicron-BA5 (weak)', 'SARS-CoV2_Omicron-BA5.9', 'SARS-CoV2_Omicron-BA5.9 (weak)'],\n",
    "    'SARS-CoV2_Omicron-XBB': ['SARS-CoV2_Omicron-XBB']\n",
    "}\n",
    "\n",
    "test_groups = ['SARS-CoV2_Omicron-BA1', 'SARS-CoV2_Omicron-BA2', 'SARS-CoV2_Omicron-BA4', \n",
    "               'SARS-CoV2_Omicron-BA5']\n",
    "\n",
    "reversed_dict = {}\n",
    "for key, value_list in grouping_dict.items():\n",
    "    for value in value_list:\n",
    "        reversed_dict[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1bb6165-ba8f-433a-83fa-f1775f5e204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df['groups'] = interaction_df['antigens'].apply(lambda x: reversed_dict.get(x, pd.NA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c8423e2-0ee4-4cb1-a5d4-3afe136349d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df = interaction_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e49ce353-4b52-41f6-9bfe-c5d9f89adef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "records = list(SeqIO.parse(\"covid_variants.fasta\", \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9ee43269-b9f7-4578-b05c-e1c1cd703a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_dict = {rec.id:str(rec.seq) for rec in records}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66ffa16f-87b9-45a2-94a2-f0b523b90b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df['covid_seq'] = interaction_df['groups'].apply(lambda x:variant_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bdb3f4c-36da-480d-b217-b6a63ea3f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df = interaction_df.drop_duplicates(subset=['names', 'groups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6276e8d8-6363-43d7-b8e9-87672cbbc7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interaction_df = interaction_df[~interaction_df['groups'].isin(test_groups)]\n",
    "test_interaction_df = interaction_df[interaction_df['groups'].isin(test_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06a34df4-e336-4a30-8f77-c41d077af82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interaction_df.to_csv('processed_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "193430bf-c653-4e40-81c9-a69d51308db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interaction_df.to_csv('processed_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd3e9c-dec5-4d18-a8ad-13c01064b915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738c25e4-8fff-4605-a4f7-6b4926582c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embs = np.load('best_embs_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e85de5-ca21-436a-af45-a7c9eda8ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interaction_df = pd.read_csv('processed_data_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b78ccd0-349b-410f-9d5e-fe1b618d7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interaction_df['prob'] = test_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "051653c7-f339-4332-a5f7-917fd6eabd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interaction_df.to_csv('covid_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5998ba0b-ec0b-42b0-a268-d0722243fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = test_interaction_df['target'].tolist()\n",
    "labels = test_interaction_df['groups'].tolist()\n",
    "names = test_interaction_df['names'].tolist()\n",
    "origins = test_interaction_df['origins'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b5050a-6b73-4530-b4a5-5d7103e4ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "def calculate_auprc_per_label(y_true, y_pred, label_types):\n",
    "    # Create a dictionary to store true labels and predictions for each label type\n",
    "    label_data = {}\n",
    "    \n",
    "    for label, true_val, pred_val in zip(label_types, y_true, y_pred):\n",
    "        if label not in label_data:\n",
    "            label_data[label] = {'y_true': [], 'y_pred': []}\n",
    "        \n",
    "        label_data[label]['y_true'].append(true_val)\n",
    "        label_data[label]['y_pred'].append(pred_val)\n",
    "    \n",
    "    # Calculate AUPRC for each label type\n",
    "    auprc_per_label = {}\n",
    "    \n",
    "    for label, data in label_data.items():\n",
    "        if len(data['y_true']) > 3:\n",
    "            precision, recall, _ = precision_recall_curve(data['y_true'], data['y_pred'])\n",
    "            auprc = auc(recall, precision)\n",
    "            auprc_per_label[label] = (auprc, np.unique(data['y_true'], return_counts=True)[1])\n",
    "    return auprc_per_label\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from functools import lru_cache\n",
    "from typing import List, Tuple, Union, Dict, Any\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    # accuracy_score, \n",
    "    precision_recall_curve, \n",
    "    # precision_score, \n",
    "    # recall_score, \n",
    "    average_precision_score, \n",
    "    roc_auc_score,\n",
    "    cohen_kappa_score,\n",
    "    # f1_score,\n",
    "    # fbeta_score,\n",
    "    # top_k_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "def fmax_score(ys: np.ndarray, preds: np.ndarray, beta = 1.0, pos_label = 1):\n",
    "    \"\"\"\n",
    "    Radivojac, P. et al. (2013). A Large-Scale Evaluation of Computational Protein Function Prediction. Nature Methods, 10(3), 221-227.\n",
    "    \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true = ys, probas_pred = preds, pos_label = pos_label)\n",
    "    # precision += 1e-4\n",
    "    # recall += 1e-4\n",
    "    # f1 = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "    # return np.nanmax(f1), thresholds[np.argmax(f1)]\n",
    "    numerator = (1 + beta**2) * (precision * recall)\n",
    "    denominator = ((beta**2 * precision) + recall)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        fbeta = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=(denominator!=0))\n",
    "    return np.nanmax(fbeta), thresholds[np.argmax(fbeta)]\n",
    "\n",
    "\n",
    "def precision_recall_at_k(y: np.ndarray, preds: np.ndarray, k: int, names: np.ndarray = None):\n",
    "    \"\"\" Calculate recall@k, precision@k, and AP@k for binary classification.\n",
    "    \"\"\"\n",
    "    assert preds.shape == y.shape\n",
    "    assert k > 0\n",
    "    \n",
    "    # Sort the scores and the labels by the scores\n",
    "    sorted_indices = np.argsort(preds.flatten())[::-1]\n",
    "    sorted_preds = preds[sorted_indices]\n",
    "    sorted_y = y[sorted_indices]\n",
    "    if names is not None:\n",
    "        sorted_names = names[sorted_indices]\n",
    "    else: sorted_names = None\n",
    "\n",
    "    # Get the scores of the k highest predictions\n",
    "    topk_preds = sorted_preds[:k]\n",
    "    topk_y = sorted_y[:k]\n",
    "    \n",
    "    # Calculate the recall@k and precision@k\n",
    "    recall_k = np.sum(topk_y, axis=-1) / np.sum(y, axis=-1)\n",
    "    precision_k = np.sum(topk_y, axis=-1) / k\n",
    "    \n",
    "    # Calculate the AP@k\n",
    "    ap_k = average_precision_score(topk_y, topk_preds)\n",
    "\n",
    "    if k > preds.shape[-1]:\n",
    "        recall_k = np.nan\n",
    "        precision_k = np.nan\n",
    "        ap_k = np.nan\n",
    "\n",
    "    return recall_k, precision_k, ap_k, (sorted_y, sorted_preds, sorted_names)\n",
    "\n",
    "\n",
    "def get_metrics_binary(preds, ys, k, verbose=False, logger=None, context=None):\n",
    "    \"\"\" Wrapper for getting binary classification metrics. If k is a float, then get top k*100% of predictions.\n",
    "    \"\"\"\n",
    "    if type(k) is float and k < 1:\n",
    "        k = int(k * ys.shape[0])\n",
    "    \n",
    "    # Efficiently compute all these metrics together\n",
    "    tn, fp, fn, tp = confusion_matrix(ys, np.round(preds)).ravel()\n",
    "    specificity = np.divide(tn, (tn + fp))\n",
    "    recall = np.divide(tp, (tp + fn))\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        npv = np.divide(tn, (tn + fn))\n",
    "        precision = np.divide(tp, (tp + fp))\n",
    "        f1 = np.divide(2 * precision * recall, (precision + recall))\n",
    "    accuracy = (tp + tn) / (tn + fn + tp + fp)\n",
    "    \n",
    "    fmax, _ = fmax_score(ys, preds)\n",
    "    recall_k, precision_k, ap_k, _ = precision_recall_at_k(ys, preds, k)\n",
    "    auroc_score = roc_auc_score(ys, preds)\n",
    "    auprc_score = average_precision_score(ys, preds)\n",
    "    mcc = matthews_corrcoef(ys, np.round(preds))\n",
    "    \n",
    "    metrics_dict = {\n",
    "        \"fmax\": fmax,\n",
    "        \"mcc\": mcc,\n",
    "        \"auroc\": auroc_score,\n",
    "        \"auprc\": auprc_score,\n",
    "        \"npv\": npv,\n",
    "        \"specificity\": specificity,\n",
    "        \"f1\": f1,\n",
    "        f\"recall@{k}\": recall_k,\n",
    "        f\"precision@{k}\": precision_k,\n",
    "        f\"ap@{k}\": ap_k,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "    \n",
    "    if context is not None and context == \"multiclass\":\n",
    "        # Cross-entropy loss\n",
    "        # ce_loss = F.cross_entropy(preds, labels, reduction='mean')\n",
    "        cohen_kappa = cohen_kappa_score(ys, np.round(preds))\n",
    "        metrics_dict[\"cohen_kappa\"] = cohen_kappa\n",
    "\n",
    "    if verbose:\n",
    "        metrics_str = ', '.join([f'{key} = {value:.4f}' for key, value in metrics_dict.items()])\n",
    "        if logger is None:\n",
    "            print(metrics_str)\n",
    "        else:\n",
    "            logger.info(metrics_str)\n",
    "    \n",
    "    return tuple(metrics_dict.values()), tuple(metrics_dict.keys())\n",
    "\n",
    "\n",
    "def get_metrics_for_indices(preds, ys, indices, k):\n",
    "    valid_ys = ys[indices]\n",
    "    valid_preds = preds[indices]\n",
    "    metrics, metric_names = get_metrics_binary(valid_preds, valid_ys, k, verbose=False)\n",
    "    return metrics, metric_names\n",
    "\n",
    "\n",
    "def get_metrics(preds: np.ndarray, ys: np.ndarray, labels: np.ndarray, k: Union[int, float] = 50, task: str = 'multilabel', logger: Any = None, average: str = \"macro\", verbose: bool = True) -> Tuple[Dict[str, Union[np.ndarray, float]], Union[np.ndarray, int]]:\n",
    "    \"\"\" Wrapper for getting classification metrics. \n",
    "    Binary & Multilabel: Accuracy, AUROC, AUPRC, precision, recall, recall@50, precision@50, ap@50, fmax, f1\n",
    "    Multiclass: Accuracy, AUROC, AUPRC, precision, recall, recall@50, precision@50, ap@50, fmax, f1, Cohen's kappa\n",
    "    \n",
    "    Args:\n",
    "        preds: Predictions from model for each sample\n",
    "        ys: Indicators for each sample being positive or negative\n",
    "        labels: Labels for each sample\n",
    "        k: Number of top predictions to consider for recall@k, precision@k, and ap@k\n",
    "        task: Type of classification task, one of 'binary', 'multilabel', or 'multiclass'\n",
    "        logger: Logger to use for printing metrics\n",
    "        average: Type of averaging to use for multilabel or multiclass metrics, one of 'macro', 'weighted', 'micro', or None\n",
    "        verbose: Whether to print metrics or not\n",
    "    \n",
    "    Returns:\n",
    "        metrics_dict: Dictionary of metrics\n",
    "        pos_samples: Number of positive samples for each class\n",
    "    \"\"\"\n",
    "    assert average is None or average in [\"macro\", \"weighted\", \"micro\"]\n",
    "    \n",
    "    if task == 'binary':\n",
    "        metrics, metric_names = get_metrics_binary(preds, ys, k, verbose=verbose, logger=logger)\n",
    "        pos_samples = sum(ys)\n",
    "        \n",
    "    else:\n",
    "        # compute macro metrics. NOTE: We use sort + return_index & return_counts to efficiently get all indices of unique values, ref: https://stackoverflow.com/questions/30003068/how-to-get-a-list-of-all-indices-of-repeated-elements-in-a-numpy-array\n",
    "        # creates an array of indices, sorted by unique element\n",
    "        idx_sort = np.argsort(labels)\n",
    "        # sorts records array so all unique elements are together \n",
    "        sorted_labels = labels[idx_sort]\n",
    "        # returns the unique values, the index of the first occurrence of a value, and the count for each element\n",
    "        vals, idx_start, count = np.unique(sorted_labels, return_counts=True, return_index=True)\n",
    "        # splits the indices into separate arrays\n",
    "        indices_grouped_list = np.split(idx_sort, idx_start[1:])\n",
    "        \n",
    "        pos_samples = np.array([sum(ys[indices]) for indices in indices_grouped_list])\n",
    "        \n",
    "        if average == 'micro':\n",
    "            metrics, metric_names = get_metrics_binary(preds, ys, k, verbose=False)\n",
    "            \n",
    "        else:\n",
    "            metrics_list = []\n",
    "            for indices in indices_grouped_list:\n",
    "                metrics, metric_names = get_metrics_for_indices(preds, ys, indices, k)\n",
    "                metrics_list.append(metrics)\n",
    "                \n",
    "            if average == 'macro':\n",
    "                metrics = np.array(metrics_list).mean(axis=0)\n",
    "            elif average == 'weighted':\n",
    "                metrics = np.array(metrics_list).T @ pos_samples / pos_samples.sum()\n",
    "            elif average is None:  # output label-stratified scores without averaging\n",
    "                metrics = np.array(metrics_list).T  # from (n_classes, n_metrics) to (n_metrics, n_classes)\n",
    "                \n",
    "        if verbose and average is not None:\n",
    "            metrics_str = ', '.join([f'{key} = {value:.4f}' for key, value in zip(metric_names, metrics)])\n",
    "            if logger is not None:\n",
    "                logger.info(metrics_str)\n",
    "\n",
    "    metrics_dict = dict(zip(metric_names, metrics))\n",
    "    return metrics_dict, pos_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08467a8-e695-425f-88a4-2f17382a0bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SARS-CoV2_Omicron-BA2': (0.6606509285766826, array([203, 144])),\n",
       " 'SARS-CoV2_Omicron-BA1': (0.638117715182259, array([253, 160])),\n",
       " 'SARS-CoV2_Omicron-BA4': (0.7433847677946852, array([24, 19])),\n",
       " 'SARS-CoV2_Omicron-BA5': (0.5383124959233341, array([192,  57]))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_auprc_per_label(targets, test_embs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71bec42f-dd12-4065-b395-d0deb4f31a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fmax': array([0.64987406, 0.66129032, 0.7       , 0.58267717]),\n",
       "  'mcc': array([0.06195148, 0.09040079, 0.19871523, 0.11654331]),\n",
       "  'auroc': array([0.75353261, 0.73611111, 0.77192982, 0.78234649]),\n",
       "  'auprc': array([0.6406075 , 0.66272152, 0.75208117, 0.54591136]),\n",
       "  'npv': array([0.61407767, 0.5884058 , 0.58974359, 0.77419355]),\n",
       "  'specificity': array([1.        , 1.        , 0.95833333, 1.        ]),\n",
       "  'f1': array([0.01242236, 0.02739726, 0.26086957, 0.03448276]),\n",
       "  'recall@50': array([0.225     , 0.22222222,        nan, 0.47368421]),\n",
       "  'precision@50': array([0.72, 0.64,  nan, 0.54]),\n",
       "  'ap@50': array([0.77454618, 0.84837508,        nan, 0.68229611]),\n",
       "  'accuracy': array([0.61501211, 0.5907781 , 0.60465116, 0.7751004 ]),\n",
       "  'precision': array([1.  , 1.  , 0.75, 1.  ]),\n",
       "  'recall': array([0.00625   , 0.01388889, 0.15789474, 0.01754386])},\n",
       " array([160, 144,  19,  57]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(np.array(test_embs), np.array(targets), np.array(labels), k=50, \n",
    "    task='multiclass',\n",
    "    average=None,\n",
    "    logger=None, \n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a212b4-2e33-49a7-b09c-47458327ad6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-cells; SARS-CoV2_WT Convalescent Patient (Unvaccinated)': (0.7638888888888888,\n",
       "  array([1, 3])),\n",
       " 'B-cells; SARS-CoV2_WT Convalescent Patients': (0.7541249810180233,\n",
       "  array([36, 48])),\n",
       " 'B-cells; SARS-CoV2_WT Vaccinee (BBIBP-CoV)': (0.5212567766441261,\n",
       "  array([47, 29])),\n",
       " 'B-cells; SARS-CoV2_WT Vaccinee': (0.914950677987415, array([ 11, 105])),\n",
       " 'B-cells; SARS-CoV2_WT Human Patient': (0.38736685044959596,\n",
       "  array([497, 162])),\n",
       " 'B-cells; Unvaccinated SARS-CoV2_WT Human Patient': (0.25, array([3, 1])),\n",
       " 'B-cells; SARS-CoV2_Gamma Human Patient': (0.7243936431689466,\n",
       "  array([37, 13])),\n",
       " 'B-cells; SARS-CoV1 Human Patient': (0.7285714285714286, array([22,  4])),\n",
       " 'B-cells (SARS-CoV2_Beta Human Patient)': (0.7629801664660999,\n",
       "  array([18, 15]))}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_auprc_per_label(targets, test_embs, origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1fa3b13-522c-446a-b810-730213ded957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fmax': array([0.71428571, 0.66666667, 0.69565217, 0.85714286, 0.78504673,\n",
       "         0.44517185, 0.95022624, 0.57731959, 0.66666667]),\n",
       "  'mcc': array([ 0.27824334,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.13687686,  0.03018233, -0.09070254,  0.        ]),\n",
       "  'auroc': array([0.75185185, 0.92045455, 0.88357588, 0.33333333, 0.72164352,\n",
       "         0.63961547, 0.59307359, 0.63609685, 0.66666667]),\n",
       "  'auprc': array([0.77003896, 0.75      , 0.7378875 , 0.80555556, 0.7588613 ,\n",
       "         0.38990009, 0.91642961, 0.54309175, 0.5       ]),\n",
       "  'npv': array([0.58064516, 0.84615385, 0.74      , 0.25      , 0.42857143,\n",
       "         0.75877863, 0.09565217, 0.61333333, 0.75      ]),\n",
       "  'specificity': array([1.       , 1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "         1.       , 0.9787234, 1.       ]),\n",
       "  'f1': array([0.23529412,        nan,        nan,        nan,        nan,\n",
       "         0.04819277, 0.01886792,        nan,        nan]),\n",
       "  'recall@50': array([       nan,        nan, 1.        ,        nan, 0.70833333,\n",
       "         0.12962963, 0.44761905, 0.75862069,        nan]),\n",
       "  'precision@50': array([ nan,  nan, 0.26,  nan, 0.68, 0.42, 0.94, 0.44,  nan]),\n",
       "  'ap@50': array([       nan,        nan, 0.7378875 ,        nan, 0.7928323 ,\n",
       "         0.69821777, 0.90032622, 0.58600346,        nan]),\n",
       "  'accuracy': array([0.60606061, 0.84615385, 0.74      , 0.25      , 0.42857143,\n",
       "         0.76024279, 0.10344828, 0.60526316, 0.75      ]),\n",
       "  'precision': array([ 1., nan, nan, nan, nan,  1.,  1.,  0., nan]),\n",
       "  'recall': array([0.13333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.02469136, 0.00952381, 0.        , 0.        ])},\n",
       " array([ 15,   4,  13,   3,  48, 162, 105,  29,   1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(np.array(test_embs), np.array(targets), np.array(origins), k=50, \n",
    "    task='multiclass',\n",
    "    average=None,\n",
    "    logger=None, \n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2f700-66fd-4fac-bbf8-ecadf236eacf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
